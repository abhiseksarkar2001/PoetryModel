{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a94134",
   "metadata": {},
   "source": [
    "# use LSTM neural networks (Long-Short-Term Memory) \n",
    "## in order to tech our computer to write sonnets like William_Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9baf80fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 16:26:21.390696: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-28 16:26:21.419048: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745837781.452167  211593 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745837781.461863  211593 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745837781.486436  211593 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745837781.486466  211593 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745837781.486470  211593 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745837781.486473  211593 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-28 16:26:21.493551: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Importing necessery packages\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ee363",
   "metadata": {},
   "source": [
    "Data Source: https://github.com/martin-gorner/tensorflow-rnn-shakespeare/blob/master/shakespeare/sonnets.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "651f7510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the text file\n",
    "filepath = '/home/abhisek/Project/sonnets.txt'\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c062e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac33e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in the text: 95662\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of characters in the text: {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f2f2c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEQ_LENGTH = how many charecters will be used to predict the next character\n",
    "SEQ_LENGTH = 40\n",
    "\n",
    "# STEP_SIZE = how many characters we want to shift to next sequence\n",
    "STEP_SIZE = 3\n",
    "\n",
    "\n",
    "# Creating empty list of sentences and next characters\n",
    "sentences = []\n",
    "next_char = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bef2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We iterate through the whole text and gather all sentences and their next character.\n",
    "# This is the training data for our neural network. \n",
    "# Now we just need to convert it into a numerical format.\n",
    "\n",
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    next_char.append(text[i + SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45fa8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting the characters\n",
    "characters = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c11af58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating two dictionaries from characters to index and from index to characters\n",
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "index_to_char= dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d3b25ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), SEQ_LENGTH,\n",
    "              len(characters)), dtype= bool)\n",
    "y = np.zeros((len(sentences),\n",
    "              len(characters)), dtype= bool)\n",
    "\n",
    "for i, satz in enumerate(sentences):\n",
    "    for t, char in enumerate(satz):\n",
    "        x[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_char[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ca2535",
   "metadata": {},
   "source": [
    "## Building Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3d930f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessery packages\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba5f0b",
   "metadata": {},
   "source": [
    "We will use Sequential for our model, Activation, Dense and LSTM for our layers and RMSprop for optimization during the compilation of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e79eabcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 16:26:26.841001: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/home/abhisek/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128,\n",
    "               input_shape=(SEQ_LENGTH,\n",
    "                            len(characters)))) # The inputs immediately flow into our LSTM layer with 128 neurons\n",
    "# Our input shape is the length of a sentence times the amount of characters.\n",
    "model.add(Dense(len(characters))) #This layer is followed by a Dense hidden layer, which just increases complexity\n",
    "model.add(Activation('softmax')) # In the end we use the Softmax activation function in order to make our results add up to one. This gives us the probability for each character."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cce6a3",
   "metadata": {},
   "source": [
    "We'll now compile and train the model for four epochs using a batch size of 256, meaning the model will iterate through the entire training data four times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06d7e135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 16:26:28.980007: E tensorflow/core/util/util.cc:131] oneDNN supports DT_BOOL only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 141ms/step - loss: 2.9207\n",
      "Epoch 2/4\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 131ms/step - loss: 2.1991\n",
      "Epoch 3/4\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 133ms/step - loss: 1.9736\n",
      "Epoch 4/4\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 131ms/step - loss: 1.8481\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "model.fit(x, y, batch_size=256, epochs=4)\n",
    "\n",
    "model.save('/home/abhisek/Project/sonnets.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69ef8aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('sonnets.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e7b8b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional functions to make our script generate some reasonable text\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d08845b",
   "metadata": {},
   "source": [
    "This function samples a character from the prediction output based on a 'temperature' parameter. Higher temperatures lead to more random (less likely) character choices, while lower temperatures result in more predictable (more likely) selections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217eeeb1",
   "metadata": {},
   "source": [
    "#### Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "386ff75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, temperature):\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_predictions[0, t, char_to_index[char]] = 1\n",
    "\n",
    "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
    "        next_index = sample(predictions,\n",
    "                                 temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3caa11c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and there appears a face\n",
      "that over-goes thy sweet shall thy sweet on the stell in the steet shall in thy sweet shall in thy sweet that beauty the sweet,\n",
      "the stell in the stelf that have the stell thou hear shall thy sweet thy sweet of thy sweet thy sweet shall thy sweet shall the steet shall thy sweet stell thy stall thy sweet of thy swe\n",
      "ning time, whose million'd accidents\n",
      "creave, thou hade of come conceet than thy sweet with thy love\n",
      "that shall for thy conseet be when thy stall thy sweet stall in my shall thy eve\n",
      "the be unor sing the sume's not still in shall the sime's thy sone,\n",
      "  and the store of hear,\n",
      "  thin thou be un that thy desseet in that head,\n",
      "that fare in the \n",
      "s loss,\n",
      "and let that pine to aggravate thy seast and my mine but my sive the sume's sime that grain i my live when with the prowes of thy swall of thinss,\n",
      "whine of thou wist the prive whe houd thee so not shall thy sweets the stwangs the stand thus sece,\n",
      "  shall mise when thy plove that in thy sime,\n",
      "which hast thou wo shall thy seas love \n",
      "ill may live in thine or thee.\n",
      "\n",
      "xi.\n",
      "\n",
      "as your hand the winter hath to thy some\n",
      "thou strowe and the sugh thou are sublets when so but of heave, that it wand of thy such strees and tile in foull of and thou sten'\n",
      "whes fintens and thou she the shall ofe the crumplecide, thus stour and the see.\n",
      "\n",
      "nxxvii.\n",
      "\n",
      "when thile no on stay that in me be not\n",
      "rive and i be cast away,\n",
      "  the worst waste sombeet thoug the frweet, shall thas my our thy flate thy stouste grount, thy some's dether faul dids beaut my swient\n",
      "buan my coou hing hourt well,\n",
      "  mor ally noth thy swale what no shell,\n",
      "that time prace of thy stoul\n",
      "when is am well well with thun the sweet,\n",
      "  the callaan will thou look what no \n",
      "e thou hadst this more.\n",
      "then if for my love, amuther coun prfapne, wat her amanntexs?\n",
      "nive ane, that i hath complease fild shall blom,\n",
      "in ne, i mine the wiph and then,\n",
      "cour parugue of thairs shall gays lovk and, of well,\n",
      "  in the streach stelte  all fear ppouty\n",
      "the stall my sone;\n",
      "but in atour wruth hor mohand spppent,\n",
      "sees of my heast is \n"
     ]
    }
   ],
   "source": [
    "# Output\n",
    "print(generate_text(300, 0.2))\n",
    "print(generate_text(300, 0.4))\n",
    "print(generate_text(300, 0.5))\n",
    "print(generate_text(300, 0.6))\n",
    "print(generate_text(300, 0.7))\n",
    "print(generate_text(300, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fca5adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, generate all outputs\n",
    "outputs = []\n",
    "outputs.append(generate_text(300, 0.2))\n",
    "outputs.append(generate_text(300, 0.4))\n",
    "outputs.append(generate_text(300, 0.5))\n",
    "outputs.append(generate_text(300, 0.6))\n",
    "outputs.append(generate_text(300, 0.7))\n",
    "outputs.append(generate_text(300, 0.8))\n",
    "\n",
    "# Now, save them into a text file\n",
    "output_path = '/home/abhisek/Project/output_sonnet.txt'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    for i, text in enumerate(outputs):\n",
    "        f.write(f\"Output for temperature {0.2 + 0.2 * i}:\\n\")\n",
    "        f.write(text)\n",
    "        f.write(\"\\n\\n\" + \"-\"*50 + \"\\n\\n\")  # separator between outputs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
