{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a94134",
   "metadata": {},
   "source": [
    "# use LSTM neural networks (Long-Short-Term Memory) \n",
    "## in order to tech our computer to write Poems like William Wordsworth and Robert Frost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf80fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 02:05:22.644251: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-28 02:05:22.683546: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745786122.715715   13795 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745786122.725460   13795 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745786122.748125   13795 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745786122.748158   13795 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745786122.748161   13795 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745786122.748163   13795 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-28 02:05:22.755807: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Importing necessery packages\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a68f83",
   "metadata": {},
   "source": [
    "Data Source : https://www.kaggle.com/datasets/charunisa/english-poems-dataset?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f7510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the text file\n",
    "filepath = '/home/abhisek/Project/poems.txt'\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c062e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac33e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in the text: 75752\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of characters in the text: {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f2c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEQ_LENGTH = how many charecters will be used to predict the next character\n",
    "SEQ_LENGTH = 40\n",
    "\n",
    "# STEP_SIZE = how many characters we want to shift to next sequence\n",
    "STEP_SIZE = 3\n",
    "\n",
    "\n",
    "# Creating empty list of sentences and next characters\n",
    "sentences = []\n",
    "next_char = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We iterate through the whole text and gather all sentences and their next character.\n",
    "# This is the training data for our neural network. \n",
    "# Now we just need to convert it into a numerical format.\n",
    "\n",
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    next_char.append(text[i + SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting the characters\n",
    "characters = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11af58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating two dictionaries from characters to index and from index to characters\n",
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "index_to_char= dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d3b25ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), SEQ_LENGTH,\n",
    "              len(characters)), dtype= bool)\n",
    "y = np.zeros((len(sentences),\n",
    "              len(characters)), dtype= bool)\n",
    "\n",
    "for i, satz in enumerate(sentences):\n",
    "    for t, char in enumerate(satz):\n",
    "        x[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_char[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ca2535",
   "metadata": {},
   "source": [
    "## Building Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d930f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessery packages\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba5f0b",
   "metadata": {},
   "source": [
    "We will use Sequential for our model, Activation, Dense and LSTM for our layers and RMSprop for optimization during the compilation of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79eabcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 11:41:53.487656: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/home/abhisek/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128,\n",
    "               input_shape=(SEQ_LENGTH,\n",
    "                            len(characters)))) # The inputs immediately flow into our LSTM layer with 128 neurons\n",
    "# Our input shape is the length of a sentence times the amount of characters.\n",
    "model.add(Dense(len(characters))) #This layer is followed by a Dense hidden layer, which just increases complexity\n",
    "model.add(Activation('softmax')) # In the end we use the Softmax activation function in order to make our results add up to one. This gives us the probability for each character."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cce6a3",
   "metadata": {},
   "source": [
    "We'll now compile and train the model for four epochs using a batch size of 256, meaning the model will iterate through the entire training data four times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d7e135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 135ms/step - loss: 1.5171\n",
      "Epoch 2/4\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 143ms/step - loss: 1.3949\n",
      "Epoch 3/4\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 144ms/step - loss: 1.3069\n",
      "Epoch 4/4\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 156ms/step - loss: 1.2125\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "model.fit(x, y, batch_size=256, epochs=4)\n",
    "\n",
    "model.save('/home/abhisek/Project/poemgenerator.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef8aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('poemgenerator.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b8b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional functions to make our script generate some reasonable text\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d08845b",
   "metadata": {},
   "source": [
    "This function samples a character from the prediction output based on a 'temperature' parameter. Higher temperatures lead to more random (less likely) character choices, while lower temperatures result in more predictable (more likely) selections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217eeeb1",
   "metadata": {},
   "source": [
    "#### Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "386ff75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, temperature):\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_predictions[0, t, char_to_index[char]] = 1\n",
    "\n",
    "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
    "        next_index = sample(predictions,\n",
    "                                 temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caa11c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "and washing dishes after them—from doing his wild reart.\n",
      "\n",
      "i have be garden you the light,\n",
      "and string with the starling fan he stop\n",
      "to seen and blowers in the stars,\n",
      "and the moundas strengm:\n",
      "there sand of the manthis would be one off seen and beart,\n",
      "where the starling fan the starniss,\n",
      "of ling, and stopted from the starf\n",
      "suchord \n",
      "w more fair:\n",
      "dull would he be of soul with the flack.\n",
      "and stan in its go dound be been withone.\n",
      "\n",
      "i have be in provised on the starl\n",
      "to so mene far in on the light be ond my hervenow.\n",
      "i gone of the births some bake when it shouse of the star all oft,\n",
      "and strown both a more to the grien sone.\n",
      "of the given at reast of all our sead.\n",
      "\n",
      "after sunset, sir,\n",
      "when it is light and beary there,\n",
      "and it i sook to see and blowers.\n",
      "i dound at like a stop and make on the star\n",
      "the warse and bodk to busent meantwryes,\n",
      "but we bight to should be then are them some.\n",
      "\n",
      "there strees ingred to be bears to sun\n",
      "the hearth spores of stownt\n",
      "when they caunt of stantime of a mistorar.\n",
      "h\n",
      "o could pass by\n",
      "a sight so touching in birts\n",
      "and it a gust seem nor to sun mear.\n",
      "\n",
      "you gain-dook howle, and boid is than sull be bed\n",
      "our her is gow a wind them once to busher arape.\n",
      "\n",
      "whowe they is its ground on them.\n",
      "what is mome of come in ming.\n",
      "\n",
      "when we doon to the mints of the blow.\n",
      "\n",
      "i fen with the may so must fan one where \n",
      "oving soul.\n",
      "--and often, trifling with the ellace of them of main daghn stowe\n",
      "but it seld on thy off of the liel of them owner ofrisen.\n",
      "\n",
      "i hould thes sead with the fon one the there's deate me.\n",
      "\n",
      "when there singal, and some rigged.\n",
      "i dound enough to be chanted they sweet\n",
      "somets not borad bood. the earth-shereno.\n",
      "ind strings in the\n",
      "in that there\n",
      "he sat and waited till he will,\n",
      "be loving come all you he had wild then sing\n",
      "the winds to sumpre in the light.\n",
      "look there, was ho bush ampleep and flowers,\n",
      "one headen fight\n",
      "so feell, is its a rand\n",
      "as in our bees, if fash and so we roors,\n",
      "nor the fornts, of flalling aten of fond\n",
      "ow hervedanood,\n",
      "and i sould the dilla\n"
     ]
    }
   ],
   "source": [
    "# Output\n",
    "print(generate_text(300, 0.2))\n",
    "print(generate_text(300, 0.4))\n",
    "print(generate_text(300, 0.5))\n",
    "print(generate_text(300, 0.6))\n",
    "print(generate_text(300, 0.7))\n",
    "print(generate_text(300, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fca5adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, generate all outputs\n",
    "outputs = []\n",
    "outputs.append(generate_text(300, 0.2))\n",
    "outputs.append(generate_text(300, 0.4))\n",
    "outputs.append(generate_text(300, 0.5))\n",
    "outputs.append(generate_text(300, 0.6))\n",
    "outputs.append(generate_text(300, 0.7))\n",
    "outputs.append(generate_text(300, 0.8))\n",
    "\n",
    "# Now, save them into a text file\n",
    "output_path = '/home/abhisek/Project/output.txt'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    for i, text in enumerate(outputs):\n",
    "        f.write(f\"Output for temperature {0.2 + 0.2 * i}:\\n\")\n",
    "        f.write(text)\n",
    "        f.write(\"\\n\\n\" + \"-\"*50 + \"\\n\\n\")  # separator between outputs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
